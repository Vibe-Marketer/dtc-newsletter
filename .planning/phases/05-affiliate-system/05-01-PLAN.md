---
phase: 05-affiliate-system
plan: 01
type: execute
wave: 1
depends_on: []
files_modified:
  - execution/affiliate_discovery.py
  - execution/pitch_generator.py
  - tests/test_affiliate_discovery.py
  - tests/test_pitch_generator.py
autonomous: true
user_setup:
  - service: anthropic
    why: "Claude API for pitch generation"
    env_vars:
      - name: ANTHROPIC_API_KEY
        source: "Anthropic Console -> API Keys"

must_haves:
  truths:
    - "Perplexity discovers relevant affiliate programs for a given topic"
    - "Each affiliate has commission rate, accessibility status, and topic fit"
    - "Claude generates contextual pitch angles matching Hormozi/Suby voice"
    - "Commission rates are classified as excellent/good/mediocre/poor"
  artifacts:
    - path: "execution/affiliate_discovery.py"
      provides: "Affiliate discovery via Perplexity API"
      exports: ["discover_affiliates", "AffiliateProgram", "classify_commission"]
    - path: "execution/pitch_generator.py"
      provides: "Pitch angle generation via Claude API"
      exports: ["generate_pitch", "generate_pitches_batch"]
  key_links:
    - from: "execution/affiliate_discovery.py"
      to: "execution/perplexity_client.py"
      via: "Uses get_client() pattern"
      pattern: "from openai import OpenAI"
    - from: "execution/pitch_generator.py"
      to: "anthropic"
      via: "Claude API for voice-matched generation"
      pattern: "anthropic\\.Anthropic\\(\\)"
---

<objective>
Build the core affiliate discovery and pitch generation modules.

Purpose: Enable topic-specific affiliate discovery and contextual pitch generation for Section 4 ("Tool of the Week").

Output: Two modules - affiliate_discovery.py (Perplexity-based discovery with structured output) and pitch_generator.py (Claude-based pitch generation with voice matching).
</objective>

<execution_context>
@~/.config/opencode/get-shit-done/workflows/execute-plan.md
@~/.config/opencode/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/phases/05-affiliate-system/05-CONTEXT.md
@.planning/phases/05-affiliate-system/05-RESEARCH.md
@execution/perplexity_client.py
</context>

<tasks>

<task type="auto">
  <name>Task 1: Create affiliate discovery module</name>
  <files>execution/affiliate_discovery.py, tests/test_affiliate_discovery.py</files>
  <action>
Create affiliate_discovery.py with:

1. **Pydantic models:**
   - `AffiliateProgram`: name, company, commission_rate (str like "20%"), commission_type (percentage|flat_fee), is_recurring (bool), product_description, topic_fit, network (ShareASale|Awin|PartnerStack|Impact|direct), signup_accessible (bool)
   - `AffiliateDiscoveryResult`: affiliates list, search_citations list, topic

2. **Core function - discover_affiliates(topic: str, newsletter_context: str = "") -> AffiliateDiscoveryResult:**
   - Use Perplexity client pattern from perplexity_client.py (OpenAI-compatible)
   - Use sonar-pro model
   - Prompt must:
     - Request 5+ affiliate programs relevant to specific topic
     - Require verification of signup accessibility (not closed/waitlisted)
     - Ask for commission rate with type (percentage vs flat) and duration (recurring vs one-time)
     - Ask for network/platform (ShareASale, Awin, PartnerStack, Impact, or direct)
     - Explain why each fits the specific topic
   - Parse JSON response into AffiliateDiscoveryResult
   - Include error handling for malformed responses (retry once)

3. **Commission classifier - classify_commission(rate: float, is_recurring: bool) -> str:**
   Per RESEARCH.md thresholds:
   - Recurring: excellent >= 20%, good >= 10%, mediocre < 10%
   - One-time: good >= 30%, mediocre >= 15%, poor < 15%

4. **Cache helper - save_affiliates(result: AffiliateDiscoveryResult, cache_dir: Path = Path("data/affiliate_cache")) -> Path:**
   - Save to data/affiliate_cache/[date]-[topic_slug]-affiliates.json
   - 24-hour TTL (per RESEARCH.md decision)

Tests (test_affiliate_discovery.py):
- Test commission classifier with all threshold boundaries
- Test discover_affiliates with mocked Perplexity response
- Test malformed response handling
- Test cache save/load
  </action>
  <verify>pytest tests/test_affiliate_discovery.py -v passes all tests</verify>
  <done>discover_affiliates() returns structured AffiliateDiscoveryResult with typed affiliate programs; commission classifier correctly categorizes rates</done>
</task>

<task type="auto">
  <name>Task 2: Create pitch generator module</name>
  <files>execution/pitch_generator.py, tests/test_pitch_generator.py</files>
  <action>
Create pitch_generator.py with:

1. **Voice profile constant:**
   ```python
   VOICE_GUIDANCE = """
   Voice requirements (Hormozi/Suby hybrid):
   - Short, punchy sentences (under 15 words typically)
   - Direct, confident, slightly irreverent tone
   - Specific numbers and math: "$X invested -> $Y returned"
   - Zero fluff - delete "basically," "essentially," "just"
   - Concrete, specific examples (never hypothetical)
   - 80% value / 20% ask ratio
   """
   ```

2. **generate_pitch(affiliate: AffiliateProgram, newsletter_topic: str, problem_context: str = "") -> str:**
   - Use Anthropic Claude API (claude-sonnet-4-20250514)
   - Generate 2-3 sentence pitch that:
     - References the specific newsletter topic/problem
     - Feels like a recommendation, not an ad
     - Ready to copy/paste into Section 4 "Tool of the Week"
     - Matches voice profile
   - Max tokens: 300

3. **generate_pitches_batch(affiliates: list[AffiliateProgram], newsletter_topic: str, problem_context: str = "") -> dict[str, str]:**
   - Generate pitches for multiple affiliates
   - Return dict mapping affiliate name to pitch
   - Handle individual failures gracefully (log warning, skip that affiliate)

4. **Anti-pattern validation - validate_pitch(pitch: str) -> bool:**
   - Check for fluff words: "basically", "essentially", "just", "simply"
   - Check for passive voice patterns
   - Check length (reject if > 4 sentences)
   - Return True if valid, False if needs regeneration

Tests (test_pitch_generator.py):
- Test pitch generation with mocked Claude response
- Test anti-pattern validation with good and bad examples
- Test batch generation with partial failures
- Test voice guidance inclusion in prompts
  </action>
  <verify>pytest tests/test_pitch_generator.py -v passes all tests</verify>
  <done>generate_pitch() returns voice-matched pitches; validation catches anti-patterns; batch generation handles failures gracefully</done>
</task>

</tasks>

<verification>
1. All tests pass: `pytest tests/test_affiliate_discovery.py tests/test_pitch_generator.py -v`
2. Import check: `python -c "from execution.affiliate_discovery import discover_affiliates, classify_commission; from execution.pitch_generator import generate_pitch"`
3. Pydantic models validate correctly
4. Commission thresholds match RESEARCH.md specifications
</verification>

<success_criteria>
1. discover_affiliates() calls Perplexity and returns structured AffiliateDiscoveryResult
2. classify_commission() correctly categorizes rates per documented thresholds
3. generate_pitch() produces voice-matched 2-3 sentence pitches via Claude
4. Anti-pattern validation catches fluff words and verbose pitches
5. All tests pass with mocked API responses
</success_criteria>

<output>
After completion, create `.planning/phases/05-affiliate-system/05-01-SUMMARY.md`
</output>
