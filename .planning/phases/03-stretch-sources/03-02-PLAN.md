---
phase: 03-stretch-sources
plan: 02
type: execute
wave: 1
depends_on: []
files_modified:
  - execution/tiktok_aggregate.py
  - execution/amazon_aggregate.py
  - directives/tiktok_aggregate.md
  - directives/amazon_aggregate.md
  - tests/test_tiktok_aggregate.py
  - tests/test_amazon_aggregate.py
autonomous: true

must_haves:
  truths:
    - "TikTok fetcher returns videos with commerce indicators or graceful failure"
    - "Amazon fetcher returns Movers & Shakers products or graceful failure"
    - "Commerce videos weighted higher in TikTok scoring"
    - "Amazon scoring captures position and velocity"
  artifacts:
    - path: "execution/tiktok_aggregate.py"
      provides: "TikTok data fetcher"
      exports: ["fetch_trending_tiktoks", "score_tiktok_video"]
    - path: "execution/amazon_aggregate.py"
      provides: "Amazon Movers & Shakers fetcher"
      exports: ["fetch_amazon_movers", "score_amazon_product"]
    - path: "directives/tiktok_aggregate.md"
      provides: "DOE directive for TikTok"
      contains: "DOE-VERSION: 2026.01.31"
    - path: "directives/amazon_aggregate.md"
      provides: "DOE directive for Amazon"
      contains: "DOE-VERSION: 2026.01.31"
  key_links:
    - from: "execution/tiktok_aggregate.py"
      to: "execution/apify_base.py"
      via: "import"
      pattern: "from execution.apify_base import"
    - from: "execution/amazon_aggregate.py"
      to: "execution/apify_base.py"
      via: "import"
      pattern: "from execution.apify_base import"
---

<objective>
Implement TikTok and Amazon Movers & Shakers aggregators as parallel stretch sources.

Purpose: TikTok surfaces viral product videos and commerce trends. Amazon surfaces trending products before they hit social media. Both add unique signals to the content mix.

Output:
- TikTok aggregator with commerce-weighted scoring
- Amazon aggregator with position + velocity scoring
- DOE directives matching script versions
</objective>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/phases/03-stretch-sources/03-RESEARCH.md
</context>

<tasks>

<task type="auto">
  <name>Task 1: TikTok Aggregator</name>
  <files>execution/tiktok_aggregate.py, directives/tiktok_aggregate.md, tests/test_tiktok_aggregate.py</files>
  <action>
Create execution/tiktok_aggregate.py:
```python
#!/usr/bin/env python3
"""
TikTok content aggregator for DTC Newsletter.
DOE-VERSION: 2026.01.31

Fetches viral TikTok videos with commerce indicators using Apify.
Surfaces trending products and creator-brand partnerships.
"""

import argparse
import os
import sys
import logging
from datetime import datetime, timezone

# Add parent directory to path for direct script execution
sys.path.insert(0, os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

from dotenv import load_dotenv
load_dotenv()

from execution.apify_base import fetch_from_apify, fetch_with_retry

logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

# Commerce-focused hashtags
COMMERCE_HASHTAGS = [
    "tiktokmademebuyit",
    "amazonfinds",
    "smallbusiness",
    "viralproducts",
    "tiktokshop",
    "dropshipping",
]

# Commerce indicator keywords
COMMERCE_KEYWORDS = [
    "link in bio", "shop now", "use code", "discount", "available at",
    "tiktok shop", "where to buy", "just restocked", "selling fast",
]

TIKTOK_ACTOR = "clockworks/tiktok-scraper"


def is_commerce_video(video: dict) -> bool:
    """
    Detect if a video has commerce indicators.
    
    Checks for:
    - TikTok Shop seller flag
    - Commerce user info
    - Sponsored content flag
    - Commerce keywords in description
    
    Args:
        video: Raw video data from Apify
    
    Returns:
        True if video has commerce indicators
    """
    # Check platform flags
    if video.get("ttSeller"):
        return True
    if video.get("isSponsored"):
        return True
    
    # Check commerce user info
    commerce_info = video.get("commerceUserInfo", {})
    if commerce_info.get("commerceUser"):
        return True
    
    # Check description for commerce keywords
    desc = (video.get("desc") or "").lower()
    for keyword in COMMERCE_KEYWORDS:
        if keyword in desc:
            return True
    
    return False


def score_tiktok_video(video: dict, hashtag_avg_plays: float = 100000.0) -> dict:
    """
    Calculate outlier score for a TikTok video.
    
    Score combines:
    - Play count ratio vs hashtag average
    - Commerce boost (1.5x for commerce videos)
    
    Args:
        video: Raw video data from Apify
        hashtag_avg_plays: Average plays for comparison (default 100k)
    
    Returns:
        Video dict with outlier_score and metadata added
    """
    play_count = video.get("playCount", 0) or 0
    like_count = video.get("diggCount", 0) or 0
    comment_count = video.get("commentCount", 0) or 0
    share_count = video.get("shareCount", 0) or 0
    
    # Base ratio vs average
    base_ratio = play_count / max(hashtag_avg_plays, 1)
    
    # Commerce boost
    is_commerce = is_commerce_video(video)
    commerce_boost = 1.5 if is_commerce else 1.0
    
    # Final score
    outlier_score = base_ratio * commerce_boost
    
    # Build video URL
    author_id = video.get("authorMeta", {}).get("id", "")
    video_id = video.get("id", "")
    url = f"https://www.tiktok.com/@{author_id}/video/{video_id}" if author_id and video_id else ""
    
    return {
        **video,
        "source": "tiktok",
        "outlier_score": round(outlier_score, 2),
        "is_commerce": is_commerce,
        "engagement": {
            "plays": play_count,
            "likes": like_count,
            "comments": comment_count,
            "shares": share_count,
        },
        "url": url,
    }


def fetch_trending_tiktoks(
    hashtags: list[str] | None = None,
    results_per_hashtag: int = 30,
) -> list[dict]:
    """
    Fetch trending TikTok videos via Apify.
    
    Args:
        hashtags: List of hashtags to search (defaults to COMMERCE_HASHTAGS)
        results_per_hashtag: Max videos per hashtag
    
    Returns:
        List of scored video dicts
    """
    tags = hashtags or COMMERCE_HASHTAGS
    
    logger.info(f"Fetching TikToks for hashtags: {tags}")
    
    run_input = {
        "hashtags": tags,
        "resultsPerPage": results_per_hashtag,
        "scrapeRelatedVideos": False,
        "shouldDownloadVideos": False,
    }
    
    items = fetch_from_apify(TIKTOK_ACTOR, run_input)
    
    # Deduplicate and score
    seen_ids = set()
    scored_videos = []
    
    for video in items:
        video_id = video.get("id")
        if video_id and video_id not in seen_ids:
            seen_ids.add(video_id)
            scored = score_tiktok_video(video)
            scored_videos.append(scored)
    
    # Sort by outlier score descending
    scored_videos.sort(key=lambda x: x.get("outlier_score", 0), reverse=True)
    
    return scored_videos


def run_tiktok_aggregation(
    min_score: float = 1.5,
    results_per_hashtag: int = 30,
) -> dict:
    """
    Run full TikTok aggregation with graceful degradation.
    
    Args:
        min_score: Minimum outlier score to include
        results_per_hashtag: Max videos per hashtag
    
    Returns:
        Dict with success status, videos, and metadata
    """
    start_time = datetime.now(timezone.utc)
    
    print("\n=== TikTok Aggregation ===")
    print(f"Started: {start_time.strftime('%Y-%m-%d %H:%M:%S UTC')}")
    print(f"Hashtags: {len(COMMERCE_HASHTAGS)}")
    print(f"Minimum outlier score: {min_score}x")
    print("-" * 40)
    
    result = fetch_with_retry(
        source_name="tiktok",
        fetch_fn=lambda: fetch_trending_tiktoks(results_per_hashtag=results_per_hashtag),
        cache_key="tiktok_commerce_videos",
    )
    
    if not result["success"]:
        print(f"\nTikTok fetch failed: {result['error']}")
        print("Pipeline will continue without TikTok data.")
        return result
    
    videos = result["items"]
    
    # Filter by minimum score
    high_score_videos = [v for v in videos if v.get("outlier_score", 0) >= min_score]
    commerce_videos = [v for v in high_score_videos if v.get("is_commerce")]
    
    print(f"\nFetched: {len(videos)} videos")
    print(f"Above {min_score}x threshold: {len(high_score_videos)}")
    print(f"Commerce videos: {len(commerce_videos)}")
    
    if high_score_videos:
        print(f"\nTop 5 videos:")
        for i, video in enumerate(high_score_videos[:5], 1):
            score = video.get("outlier_score", 0)
            desc = (video.get("desc") or "")[:60] + "..." if len(video.get("desc") or "") > 60 else video.get("desc", "")
            commerce_tag = " [COMMERCE]" if video.get("is_commerce") else ""
            print(f"  {i}. [{score:.1f}x]{commerce_tag} {desc}")
    
    end_time = datetime.now(timezone.utc)
    duration = (end_time - start_time).total_seconds()
    
    print(f"\nCompleted in {duration:.1f}s")
    print("-" * 40)
    
    return {
        **result,
        "items": high_score_videos,
        "total_fetched": len(videos),
        "commerce_count": len(commerce_videos),
        "duration_seconds": duration,
    }


def parse_args() -> argparse.Namespace:
    """Parse command line arguments."""
    parser = argparse.ArgumentParser(
        description="Aggregate trending TikTok videos with commerce focus"
    )
    parser.add_argument(
        "--min-score",
        type=float,
        default=1.5,
        help="Minimum outlier score (default: 1.5)",
    )
    parser.add_argument(
        "--results-per-hashtag",
        type=int,
        default=30,
        help="Max videos per hashtag (default: 30)",
    )
    return parser.parse_args()


def main() -> int:
    """Main entry point."""
    args = parse_args()
    result = run_tiktok_aggregation(
        min_score=args.min_score,
        results_per_hashtag=args.results_per_hashtag,
    )
    return 0 if result.get("success") else 1


if __name__ == "__main__":
    sys.exit(main())
```

Create directives/tiktok_aggregate.md:
```markdown
# TikTok Content Aggregation
<!-- DOE-VERSION: 2026.01.31 -->

## Goal
Fetch viral TikTok videos with commerce indicators to surface trending products before they hit other platforms.

## Trigger Phrases
- "get tiktok trends"
- "fetch tiktok videos"
- "tiktok aggregation"
- "run tiktok aggregate"

## Quick Start
```bash
python execution/tiktok_aggregate.py
python execution/tiktok_aggregate.py --min-score 2.0
```

## What It Does
1. Searches TikTok for commerce-focused hashtags via Apify
2. Detects commerce indicators (TikTok Shop, sponsored, keywords)
3. Applies 1.5x boost for commerce videos
4. Returns scored videos sorted by outlier score

## CLI Options
| Flag | Default | Description |
|------|---------|-------------|
| --min-score | 1.5 | Minimum outlier score threshold |
| --results-per-hashtag | 30 | Max videos per hashtag |

## Output
- Console display of top videos with scores
- Commerce videos tagged with [COMMERCE]
- Returns dict with: success, items, commerce_count, duration_seconds
- Graceful degradation on failure

## Unique Value
TikTok surfaces:
- Products going viral before Amazon/Google trends
- Creator-brand partnerships and collaborations
- TikTok Shop trending items
- "TikTok made me buy it" products
```

Create basic tests/test_tiktok_aggregate.py for scoring logic.
  </action>
  <verify>
```bash
python -c "from execution.tiktok_aggregate import score_tiktok_video, is_commerce_video; print('TikTok module OK')"
grep "DOE-VERSION: 2026.01.31" execution/tiktok_aggregate.py
grep "DOE-VERSION: 2026.01.31" directives/tiktok_aggregate.md
```
  </verify>
  <done>
- tiktok_aggregate.py imports and exports correctly
- is_commerce_video detects commerce indicators
- Commerce videos get 1.5x score boost
- DOE directive matches script version
  </done>
</task>

<task type="auto">
  <name>Task 2: Amazon Movers & Shakers Aggregator</name>
  <files>execution/amazon_aggregate.py, directives/amazon_aggregate.md, tests/test_amazon_aggregate.py</files>
  <action>
Create execution/amazon_aggregate.py:
```python
#!/usr/bin/env python3
"""
Amazon Movers & Shakers aggregator for DTC Newsletter.
DOE-VERSION: 2026.01.31

Fetches trending products from Amazon's Movers & Shakers using Apify.
Tracks velocity to surface products before they go viral on social.
"""

import argparse
import os
import sys
import logging
from datetime import datetime, timezone

# Add parent directory to path for direct script execution
sys.path.insert(0, os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

from dotenv import load_dotenv
load_dotenv()

from execution.apify_base import fetch_from_apify, fetch_with_retry

logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

# Movers & Shakers URLs - category agnostic, track what's moving fastest
MOVERS_URLS = [
    "https://www.amazon.com/gp/movers-and-shakers/",
    "https://www.amazon.com/gp/movers-and-shakers/beauty/",
    "https://www.amazon.com/gp/movers-and-shakers/hpc/",  # Health & Personal Care
    "https://www.amazon.com/gp/movers-and-shakers/sporting-goods/",
    "https://www.amazon.com/gp/movers-and-shakers/home-garden/",
]

AMAZON_ACTOR = "junglee/amazon-bestsellers"


def score_amazon_product(product: dict, category_size: int = 100) -> dict:
    """
    Calculate outlier score for an Amazon product.
    
    Hybrid scoring:
    - Position score: lower rank = higher score (inverted)
    - Velocity score: percentage gain in sales rank
    
    Args:
        product: Raw product data from Apify
        category_size: Expected items in category for normalization
    
    Returns:
        Product dict with outlier_score and metadata added
    """
    # Position in Movers & Shakers (1 = best)
    position = product.get("position", 100)
    if isinstance(position, str):
        position = int(position.replace("#", "").strip() or 100)
    
    # Sales rank change (e.g., "+1,234%" or "1234%")
    rank_change_str = product.get("rankChange", "0%")
    rank_change = 0
    try:
        # Parse percentage (handle "+1,234%" format)
        clean = rank_change_str.replace("+", "").replace(",", "").replace("%", "")
        rank_change = float(clean) if clean else 0
    except (ValueError, AttributeError):
        pass
    
    # Position score: top 10 = high score, bottom = low
    position_score = max(0, (category_size - position) / category_size)
    
    # Velocity score: percentage gain normalized (100% = 1.0, 1000% = 10.0)
    velocity_score = rank_change / 100.0
    
    # Combined score (velocity-weighted)
    # High velocity + good position = highest score
    outlier_score = (position_score * 0.3) + (velocity_score * 0.7)
    
    return {
        **product,
        "source": "amazon",
        "outlier_score": round(outlier_score, 2),
        "position": position,
        "rank_change_pct": rank_change,
        "url": product.get("url", ""),
    }


def fetch_amazon_movers(
    category_urls: list[str] | None = None,
) -> list[dict]:
    """
    Fetch Movers & Shakers products via Apify.
    
    Args:
        category_urls: List of M&S category URLs (defaults to MOVERS_URLS)
    
    Returns:
        List of scored product dicts
    """
    urls = category_urls or MOVERS_URLS
    
    logger.info(f"Fetching Amazon Movers & Shakers from {len(urls)} categories")
    
    run_input = {
        "startUrls": [{"url": url} for url in urls],
    }
    
    items = fetch_from_apify(AMAZON_ACTOR, run_input)
    
    # Deduplicate by ASIN and score
    seen_asins = set()
    scored_products = []
    
    for product in items:
        asin = product.get("asin")
        if asin and asin not in seen_asins:
            seen_asins.add(asin)
            scored = score_amazon_product(product)
            scored_products.append(scored)
    
    # Sort by outlier score descending
    scored_products.sort(key=lambda x: x.get("outlier_score", 0), reverse=True)
    
    return scored_products


def run_amazon_aggregation(
    min_score: float = 1.0,
) -> dict:
    """
    Run full Amazon aggregation with graceful degradation.
    
    Args:
        min_score: Minimum outlier score to include
    
    Returns:
        Dict with success status, products, and metadata
    """
    start_time = datetime.now(timezone.utc)
    
    print("\n=== Amazon Movers & Shakers Aggregation ===")
    print(f"Started: {start_time.strftime('%Y-%m-%d %H:%M:%S UTC')}")
    print(f"Categories: {len(MOVERS_URLS)}")
    print(f"Minimum outlier score: {min_score}x")
    print("-" * 40)
    
    result = fetch_with_retry(
        source_name="amazon",
        fetch_fn=fetch_amazon_movers,
        cache_key="amazon_movers_shakers",
    )
    
    if not result["success"]:
        print(f"\nAmazon fetch failed: {result['error']}")
        print("Pipeline will continue without Amazon data.")
        return result
    
    products = result["items"]
    
    # Filter by minimum score
    high_score_products = [p for p in products if p.get("outlier_score", 0) >= min_score]
    
    # Group by category for insight
    categories = set()
    for p in high_score_products:
        cat = p.get("category", "Unknown")
        if cat:
            categories.add(cat)
    
    print(f"\nFetched: {len(products)} products")
    print(f"Above {min_score}x threshold: {len(high_score_products)}")
    print(f"Categories represented: {len(categories)}")
    
    if high_score_products:
        print(f"\nTop 5 movers:")
        for i, product in enumerate(high_score_products[:5], 1):
            score = product.get("outlier_score", 0)
            title = (product.get("title") or "")[:50] + "..." if len(product.get("title") or "") > 50 else product.get("title", "")
            change = product.get("rank_change_pct", 0)
            pos = product.get("position", "?")
            print(f"  {i}. [{score:.1f}x] #{pos} (+{change:.0f}%) {title}")
    
    end_time = datetime.now(timezone.utc)
    duration = (end_time - start_time).total_seconds()
    
    print(f"\nCompleted in {duration:.1f}s")
    print("-" * 40)
    
    return {
        **result,
        "items": high_score_products,
        "total_fetched": len(products),
        "categories": list(categories),
        "duration_seconds": duration,
    }


def parse_args() -> argparse.Namespace:
    """Parse command line arguments."""
    parser = argparse.ArgumentParser(
        description="Aggregate trending products from Amazon Movers & Shakers"
    )
    parser.add_argument(
        "--min-score",
        type=float,
        default=1.0,
        help="Minimum outlier score (default: 1.0)",
    )
    return parser.parse_args()


def main() -> int:
    """Main entry point."""
    args = parse_args()
    result = run_amazon_aggregation(min_score=args.min_score)
    return 0 if result.get("success") else 1


if __name__ == "__main__":
    sys.exit(main())
```

Create directives/amazon_aggregate.md:
```markdown
# Amazon Movers & Shakers Aggregation
<!-- DOE-VERSION: 2026.01.31 -->

## Goal
Fetch trending products from Amazon's Movers & Shakers to surface products before they go viral on social media.

## Trigger Phrases
- "get amazon trends"
- "fetch amazon movers"
- "amazon aggregation"
- "run amazon aggregate"

## Quick Start
```bash
python execution/amazon_aggregate.py
python execution/amazon_aggregate.py --min-score 2.0
```

## What It Does
1. Scrapes Amazon Movers & Shakers pages via Apify
2. Extracts position and sales rank change percentage
3. Calculates velocity-weighted outlier score
4. Returns products sorted by momentum

## CLI Options
| Flag | Default | Description |
|------|---------|-------------|
| --min-score | 1.0 | Minimum outlier score threshold |

## Output
- Console display of top movers with position and velocity
- Returns dict with: success, items, categories, duration_seconds
- Graceful degradation on failure

## Scoring
- Position score (30%): Top 10 rank = higher score
- Velocity score (70%): Percentage gain in sales rank
- Products with +1000% gains rank highest

## Unique Value
Amazon surfaces:
- Products trending before social media catches on
- Category-agnostic velocity tracking
- Price point and review data for product ideas
- Real purchase intent signals (not just views)
```

Create basic tests/test_amazon_aggregate.py for scoring logic.
  </action>
  <verify>
```bash
python -c "from execution.amazon_aggregate import score_amazon_product, fetch_amazon_movers; print('Amazon module OK')"
grep "DOE-VERSION: 2026.01.31" execution/amazon_aggregate.py
grep "DOE-VERSION: 2026.01.31" directives/amazon_aggregate.md
```
  </verify>
  <done>
- amazon_aggregate.py imports and exports correctly
- Scoring combines position (30%) and velocity (70%)
- Handles percentage parsing from various formats
- DOE directive matches script version
  </done>
</task>

</tasks>

<verification>
```bash
# All modules import correctly
python -c "from execution.tiktok_aggregate import run_tiktok_aggregation; print('TikTok OK')"
python -c "from execution.amazon_aggregate import run_amazon_aggregation; print('Amazon OK')"

# DOE versions match
grep "DOE-VERSION: 2026.01.31" execution/tiktok_aggregate.py
grep "DOE-VERSION: 2026.01.31" execution/amazon_aggregate.py
grep "DOE-VERSION: 2026.01.31" directives/tiktok_aggregate.md
grep "DOE-VERSION: 2026.01.31" directives/amazon_aggregate.md

# Scoring tests pass
python -m pytest tests/test_tiktok_aggregate.py tests/test_amazon_aggregate.py -v 2>/dev/null || echo "Run with APIFY_TOKEN for integration tests"
```
</verification>

<success_criteria>
1. execution/tiktok_aggregate.py exports fetch_trending_tiktoks, score_tiktok_video, is_commerce_video
2. execution/amazon_aggregate.py exports fetch_amazon_movers, score_amazon_product
3. Commerce detection works for TikTok Shop, sponsored, keywords
4. Amazon scoring weights velocity (70%) over position (30%)
5. Both scripts run and return results (or graceful failure)
6. DOE directives have matching versions (2026.01.31)
</success_criteria>

<output>
After completion, create `.planning/phases/03-stretch-sources/03-02-SUMMARY.md`
</output>
