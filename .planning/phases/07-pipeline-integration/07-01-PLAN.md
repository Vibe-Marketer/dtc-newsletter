---
phase: 07-pipeline-integration
plan: 01
type: execute
wave: 1
depends_on: []
files_modified:
  - execution/cost_tracker.py
  - tests/test_cost_tracker.py
autonomous: true

must_haves:
  truths:
    - "Cost is calculated from Claude API response.usage"
    - "Cost is logged to persistent data/cost_log.json"
    - "Cost warnings appear at $1/operation and $10/run"
    - "Cumulative costs are tracked across runs"
  artifacts:
    - path: "execution/cost_tracker.py"
      provides: "Cost calculation, logging, and warning functions"
      exports: ["calculate_cost", "log_run_cost", "CostTracker"]
    - path: "tests/test_cost_tracker.py"
      provides: "Cost tracker tests"
      min_lines: 80
  key_links:
    - from: "execution/cost_tracker.py"
      to: "data/cost_log.json"
      via: "JSON file read/write"
      pattern: "cost_log\\.json"
---

<objective>
Create cost tracking module for pipeline integration with Claude API cost calculation, persistent logging, and cost warnings.

Purpose: Enable real-time cost visibility and cumulative tracking across pipeline runs. This foundation is required before building the main orchestrator.

Output: Working cost_tracker.py module with tests, ready for integration into pipeline stages.
</objective>

<execution_context>
@~/.config/Claude/get-shit-done/workflows/execute-plan.md
@~/.config/Claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/phases/07-pipeline-integration/07-CONTEXT.md
@.planning/phases/07-pipeline-integration/07-RESEARCH.md

# Existing cost logging pattern (extend, don't replace)
@execution/doe_utils.py

# Claude client for understanding response.usage structure
@execution/claude_client.py
</context>

<tasks>

<task type="auto">
  <name>Task 1: Create cost_tracker.py module</name>
  <files>execution/cost_tracker.py</files>
  <action>
Create cost tracking module with:

1. **CLAUDE_PRICING dict** - Claude Sonnet 4.5 pricing:
   - input: $3.00/MTok
   - output: $15.00/MTok  
   - cache_read: $0.30/MTok (10% of input)
   - cache_write: $3.75/MTok (1.25x input)

2. **calculate_cost(response) -> float** - Extract cost from Claude API response:
   - Access response.usage for tokens
   - Handle cache_read_input_tokens and cache_creation_input_tokens if present
   - Return total cost in USD

3. **CostTracker class** - Track costs across a pipeline run:
   - `__init__()` - Initialize with empty costs dict and run_id (timestamp)
   - `add_cost(stage: str, cost: float)` - Add cost for a stage
   - `get_stage_cost(stage: str)` - Get cost for specific stage
   - `get_total()` - Sum all costs
   - `check_warning()` - Return warning message if thresholds exceeded
   - `to_dict()` - Export as dict for logging

4. **Cost warning thresholds**:
   - OPERATION_WARNING_THRESHOLD = 1.00 (warn if single operation > $1)
   - RUN_WARNING_THRESHOLD = 10.00 (warn if total run > $10)

5. **log_run_cost(tracker: CostTracker, workflow: str)** - Persist to data/cost_log.json:
   - Load existing log or create new structure: {"runs": [], "cumulative": {}}
   - Append new run entry with timestamp, workflow, costs dict, total
   - Update cumulative totals per service
   - Write back to file with indent=2

6. **get_cumulative_costs()** - Read cumulative from log file

DO NOT use .tmp/ directory - use data/cost_log.json per CONTEXT.md specification.
Use pathlib.Path for all file operations.
Add DOE-VERSION: 2026.01.31 in docstring.
  </action>
  <verify>
python -c "from execution.cost_tracker import calculate_cost, log_run_cost, CostTracker, CLAUDE_PRICING; print('Imports OK')"
  </verify>
  <done>
Module imports without error, all functions defined with correct signatures.
  </done>
</task>

<task type="auto">
  <name>Task 2: Create cost_tracker tests</name>
  <files>tests/test_cost_tracker.py</files>
  <action>
Create comprehensive tests for cost_tracker module:

1. **test_claude_pricing_values** - Verify pricing dict has correct keys and reasonable values

2. **test_calculate_cost_basic** - Mock response with usage object:
   - input_tokens=1000, output_tokens=500
   - Expected: 1000 * 3/1M + 500 * 15/1M = 0.003 + 0.0075 = 0.0105

3. **test_calculate_cost_with_cache** - Mock response with cache tokens:
   - cache_read_input_tokens=500, cache_creation_input_tokens=200
   - Verify cache costs added correctly

4. **test_cost_tracker_add_and_total** - Test CostTracker class:
   - Add costs for multiple stages
   - Verify get_total() sums correctly
   - Verify get_stage_cost() returns correct value

5. **test_cost_tracker_warning_operation** - Add cost > $1, verify warning

6. **test_cost_tracker_warning_run** - Add costs totaling > $10, verify warning

7. **test_cost_tracker_no_warning** - Normal costs, no warning

8. **test_log_run_cost_new_file** - Log to non-existent file (creates it)
   - Use tmp_path fixture
   - Verify JSON structure: {"runs": [...], "cumulative": {...}}

9. **test_log_run_cost_append** - Log to existing file (appends)
   - Verify run count increases
   - Verify cumulative updates

10. **test_get_cumulative_costs** - Read back cumulative totals

Use pytest fixtures for mock responses and tmp_path for file operations.
  </action>
  <verify>
pytest tests/test_cost_tracker.py -v
  </verify>
  <done>
All tests pass. At least 10 test functions covering calculate_cost, CostTracker, and log_run_cost.
  </done>
</task>

</tasks>

<verification>
1. `python -c "from execution.cost_tracker import *"` - Module imports
2. `pytest tests/test_cost_tracker.py -v` - All tests pass
3. Manual verification: Cost calculation matches expected formula
</verification>

<success_criteria>
- cost_tracker.py exists with all specified functions
- CLAUDE_PRICING matches research values ($3/$15 per MTok)
- CostTracker class tracks costs and generates warnings at thresholds
- log_run_cost writes to data/cost_log.json (not .tmp/)
- All tests pass (10+ tests)
</success_criteria>

<output>
After completion, create `.planning/phases/07-pipeline-integration/07-01-SUMMARY.md`
</output>
