---
phase: 07-pipeline-integration
plan: 02
type: execute
wave: 2
depends_on: ["07-01"]
files_modified:
  - execution/pipeline_runner.py
  - tests/test_pipeline_runner.py
autonomous: true

must_haves:
  truths:
    - "Single command runs the full pipeline"
    - "Pipeline continues if a source fails (graceful degradation)"
    - "Progress is shown by default with stage announcements"
    - "Claude API calls retry 3x with exponential backoff"
    - "Cost is tracked per stage and displayed at end"
  artifacts:
    - path: "execution/pipeline_runner.py"
      provides: "Pipeline orchestration with stages"
      exports: ["run_pipeline", "PipelineResult"]
    - path: "tests/test_pipeline_runner.py"
      provides: "Pipeline orchestration tests"
      min_lines: 100
  key_links:
    - from: "execution/pipeline_runner.py"
      to: "execution/content_aggregate.py"
      via: "import and function call"
      pattern: "content_aggregate"
    - from: "execution/pipeline_runner.py"
      to: "execution/newsletter_generator.py"
      via: "import and function call"
      pattern: "newsletter_generator"
    - from: "execution/pipeline_runner.py"
      to: "execution/cost_tracker.py"
      via: "import CostTracker"
      pattern: "CostTracker"
---

<objective>
Create the main pipeline orchestrator that integrates content aggregation, newsletter generation, and affiliate discovery with graceful degradation and retry logic.

Purpose: Provide the single-command interface to run the full newsletter pipeline, with proper error handling and cost tracking.

Output: Working pipeline_runner.py with CLI interface and comprehensive tests.
</objective>

<execution_context>
@~/.config/Claude/get-shit-done/workflows/execute-plan.md
@~/.config/Claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/phases/07-pipeline-integration/07-CONTEXT.md
@.planning/phases/07-pipeline-integration/07-RESEARCH.md

# Cost tracking from Plan 01 (required dependency)
@execution/cost_tracker.py

# Modules to orchestrate
@execution/content_aggregate.py
@execution/newsletter_generator.py
@execution/affiliate_finder.py

# Claude client for understanding retry patterns
@execution/claude_client.py
</context>

<tasks>

<task type="auto">
  <name>Task 1: Create pipeline_runner.py orchestrator</name>
  <files>execution/pipeline_runner.py</files>
  <action>
Create the main pipeline orchestrator with:

1. **Imports and setup**:
   - Import tenacity for retry: `from tenacity import retry, stop_after_attempt, wait_exponential, retry_if_exception_type`
   - Import cost_tracker: CostTracker, calculate_cost, log_run_cost
   - Import pipeline stages: content_aggregate, newsletter_generator, affiliate_finder
   - Set DOE-VERSION: 2026.01.31 in docstring

2. **PipelineResult dataclass**:
   ```python
   @dataclass
   class PipelineResult:
       success: bool
       newsletter_path: Optional[Path]
       content_count: int
       costs: dict  # stage -> cost
       total_cost: float
       warnings: list[str]
       errors: list[str]
   ```

3. **announce(msg, quiet=False)** - Print stage announcements unless quiet mode

4. **Retry decorator for Claude API calls**:
   ```python
   @retry(
       stop=stop_after_attempt(3),
       wait=wait_exponential(multiplier=1, min=1, max=4),
       retry=retry_if_exception_type((anthropic.APIError, anthropic.APIConnectionError)),
       reraise=True
   )
   def call_with_retry(func, *args, **kwargs):
       return func(*args, **kwargs)
   ```

5. **Stage functions with graceful degradation**:
   
   a. **stage_content_aggregation(args, tracker, quiet)** -> dict:
      - Call content_aggregate functions
      - Track cost via tracker.add_cost("content_aggregation", cost)
      - Return {"content": [...], "topic": str} or None on failure
      - Log warning on failure, don't raise
   
   b. **stage_newsletter_generation(content, args, tracker, quiet)** -> NewsletterOutput:
      - Requires content from stage 1
      - Call newsletter_generator with retry wrapper
      - Track cost
      - Return NewsletterOutput or None on failure
   
   c. **stage_affiliate_discovery(topic, tracker, quiet)** -> dict:
      - Optional stage (continue even if fails)
      - Call affiliate_finder
      - Track cost
      - Return results or None

6. **run_pipeline(topic=None, quiet=False, verbose=False) -> PipelineResult**:
   - Initialize CostTracker
   - Run stages sequentially with graceful degradation
   - Collect warnings and errors
   - Log costs at end via log_run_cost()
   - Return PipelineResult

7. **CLI with argparse**:
   - `-q, --quiet`: Suppress progress output
   - `-v, --verbose`: Show debug output
   - `--topic TEXT`: Override auto-detected topic
   - `--skip-affiliates`: Skip affiliate discovery stage
   - `--dry-run`: Show what would run without executing (for debugging)

8. **Main execution**:
   - Parse args
   - Call run_pipeline
   - Print summary with costs
   - Exit with code 0 on success, 1 on failure

Pattern from RESEARCH.md for stage execution:
- Announce stage start
- Try execution with retry for Claude calls
- Catch exceptions, log warning, continue
- Announce stage end with cost

DO NOT fail the pipeline if optional stages fail. Only fail if ALL content sources fail.
  </action>
  <verify>
python execution/pipeline_runner.py --help
python -c "from execution.pipeline_runner import run_pipeline, PipelineResult; print('Imports OK')"
  </verify>
  <done>
CLI shows help with all flags. Module imports without error.
  </done>
</task>

<task type="auto">
  <name>Task 2: Create pipeline_runner tests</name>
  <files>tests/test_pipeline_runner.py</files>
  <action>
Create comprehensive tests for pipeline_runner:

1. **test_pipeline_result_dataclass** - Verify PipelineResult fields

2. **test_announce_prints** - Verify announce() prints when not quiet
   - Use capsys to capture output

3. **test_announce_quiet** - Verify announce() is silent in quiet mode

4. **test_stage_content_aggregation_success** - Mock content_aggregate to return data
   - Verify tracker.add_cost called
   - Verify content returned

5. **test_stage_content_aggregation_failure** - Mock content_aggregate to raise
   - Verify returns None (graceful degradation)
   - Verify warning logged

6. **test_stage_newsletter_generation_success** - Mock newsletter_generator
   - Verify NewsletterOutput returned
   - Verify cost tracked

7. **test_stage_newsletter_generation_with_retry** - Mock to fail twice then succeed
   - Verify retry mechanism works
   - Verify final success

8. **test_stage_newsletter_generation_retry_exhausted** - Mock to fail 3 times
   - Verify returns None after max retries
   - Verify error logged

9. **test_stage_affiliate_discovery_optional** - Verify pipeline continues if affiliates fail

10. **test_run_pipeline_full_success** - Mock all stages to succeed
    - Verify PipelineResult.success = True
    - Verify costs accumulated
    - Verify log_run_cost called

11. **test_run_pipeline_partial_failure** - Mock one source to fail
    - Verify pipeline continues with available data
    - Verify warnings captured

12. **test_run_pipeline_total_failure** - Mock all content sources to fail
    - Verify PipelineResult.success = False
    - Verify errors captured

13. **test_cli_help** - subprocess call with --help
    - Verify exits 0, shows usage

14. **test_cli_dry_run** - Verify --dry-run doesn't execute stages

Use pytest fixtures for mocking. Use monkeypatch for module-level mocks.
  </action>
  <verify>
pytest tests/test_pipeline_runner.py -v
  </verify>
  <done>
All tests pass. At least 14 test functions covering all stages and edge cases.
  </done>
</task>

</tasks>

<verification>
1. `python execution/pipeline_runner.py --help` - Shows CLI usage
2. `pytest tests/test_pipeline_runner.py -v` - All tests pass
3. `python execution/pipeline_runner.py --dry-run` - Shows stages without executing
</verification>

<success_criteria>
- pipeline_runner.py exists with run_pipeline() and CLI
- Graceful degradation: pipeline continues if sources fail
- Retry: Claude API calls retry 3x with backoff
- Cost tracking: Each stage's cost tracked via CostTracker
- All tests pass (14+ tests)
</success_criteria>

<output>
After completion, create `.planning/phases/07-pipeline-integration/07-02-SUMMARY.md`
</output>
